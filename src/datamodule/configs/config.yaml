# dataset split: the rest goes for training
seed: 1
split:
    val: 0.1
    test: 0.2
    
# dataloader params
train_loader:
    batch_size: 32
    pin_memory: true
    num_workers: 8
    shuffle: true
val_loader:
    batch_size: 32
    pin_memory: true
    num_workers: 8
    shuffle: false
test_loader:
    batch_size: 32
    pin_memory: true
    num_workers: 8
    shuffle: false

    
# transforms
train_transforms:
    RandomCrop: 
        height: 280
        width: 280
        always_apply: true
    Blur:
        blur_limit: 9
        p: .33
    Normalize:
        mean: 
            - 0.485
            - 0.456
            - 0.406
        std:
            - 0.229
            - 0.224
            - 0.225
        max_pixel_value: 255.0
        always_apply: true
    ToTensorV2:
        always_apply: true
val_transforms:
    RandomCrop: 
        height: 280
        width: 280
        always_apply: true
    Normalize:
        mean: 
            - 0.485
            - 0.456
            - 0.406
        std:
            - 0.229
            - 0.224
            - 0.225
        max_pixel_value: 255.0
        always_apply: true
    ToTensorV2:
        always_apply: true
test_transforms:
    RandomCrop: 
        height: 280
        width: 280
        always_apply: true
    Normalize:
        mean: 
            - 0.485
            - 0.456
            - 0.406
        std:
            - 0.229
            - 0.224
            - 0.225
        max_pixel_value: 255.0
        always_apply: true
    ToTensorV2:
        always_apply: true